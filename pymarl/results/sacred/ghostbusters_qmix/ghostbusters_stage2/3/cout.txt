[INFO 17:24:19] pymarl Running command 'my_main'
[INFO 17:24:19] pymarl Started run with ID "3"
[DEBUG 17:24:19] pymarl Starting Heartbeat
[DEBUG 17:24:19] my_main Started
[WARNING 17:24:19] my_main CUDA flag use_cuda was switched OFF automatically because no CUDA devices are available!
[INFO 17:24:19] my_main Experiment Parameters:
[INFO 17:24:19] my_main 

{   'action_selector': 'epsilon_greedy',
    'add_value_last_step': True,
    'agent': 'rnn',
    'agent_output_type': 'q',
    'batch_size': 64,
    'batch_size_run': 1,
    'buffer_cpu_only': True,
    'buffer_size': 50000,
    'checkpoint_path': 'results/models/QMIX_Stage3_FullObvCatchOnlyWinner',
    'common_reward': True,
    'critic_lr': 0.0003,
    'double_q': True,
    'env': 'ghostbusters',
    'env_args': {   'episode_limit': 300,
                    'extraction_br': [   29,
                                         29],
                    'extraction_tl': [   25,
                                         25],
                    'ghost_move_prob': 1,
                    'height': 30,
                    'key': 'ghostbusters_stage2',
                    'lambda_agent_dist_to_ghost': 1.0,
                    'lambda_ghost_dist_to_extraction': 0.1,
                    'lambda_quadrant_coverage': 0.7,
                    'map_name': 'ghostbusters_stage2',
                    'n_agents': 3,
                    'render': False,
                    'render_every': 1,
                    'reward_kill': 100,
                    'reward_new_surround': 10,
                    'reward_surrounded': 5,
                    'seed': 4218301,
                    'spawn_radius': 15,
                    'width': 30},
    'epsilon_anneal_time': 300000,
    'epsilon_finish': 0.05,
    'epsilon_start': 1.0,
    'evaluate': True,
    'evaluation_epsilon': 0.1,
    'gamma': 0.99,
    'grad_norm_clip': 5,
    'hidden_dim': 64,
    'hypergroup': None,
    'hypernet_embed': 64,
    'hypernet_layers': 2,
    'label': 'default_label',
    'learner': 'q_learner',
    'learner_log_interval': 2000,
    'load_step': 0,
    'local_results_path': 'results',
    'log_interval': 2000,
    'lr': 0.0003,
    'mac': 'basic_mac',
    'mask_before_softmax': False,
    'mixer': 'qmix',
    'mixing_embed_dim': 32,
    'name': 'ghostbusters_qmix',
    'obs_agent_id': False,
    'obs_last_action': False,
    'optim_alpha': 0.99,
    'optim_eps': 1e-05,
    'optimizer': 'adam',
    'render': True,
    'repeat_id': 1,
    'reward_scalarisation': 'sum',
    'reward_standardisation_alpha': 0.01,
    'rnn_hidden_dim': 128,
    'runner': 'episode',
    'runner_log_interval': 2000,
    'save_model': True,
    'save_model_interval': 50000,
    'save_replay': False,
    'seed': 4218301,
    'standardise_returns': False,
    'standardise_rewards': True,
    'state_last_action': False,
    't_max': 600000,
    'target_update_interval': 200,
    'target_update_interval_or_tau': 200,
    'tau': 0.005,
    'test_greedy': True,
    'test_interval': 10000,
    'test_nepisode': 20,
    'use_cuda': False,
    'use_rnn': True,
    'use_tensorboard': False,
    'use_wandb': False,
    'wandb_mode': 'offline',
    'wandb_project': None,
    'wandb_save_model': False,
    'wandb_team': None}

[GhostbustersEnv] Unused env args ignored: ['ghost_move_prob', 'spawn_radius', 'reward_kill', 'reward_surrounded', 'reward_new_surround', 'lambda_quadrant_coverage', 'lambda_ghost_dist_to_extraction', 'lambda_agent_dist_to_ghost', 'render', 'render_every', 'reward_scalarisation']

===== DEBUG ARGS =====
action_selector: epsilon_greedy
add_value_last_step: True
agent: rnn
agent_output_type: q
batch_size: 64
batch_size_run: 1
buffer_cpu_only: True
buffer_size: 50000
checkpoint_path: results/models/QMIX_Stage3_FullObvCatchOnlyWinner
common_reward: True
critic_lr: 0.0003
device: cpu
double_q: True
env: ghostbusters
env_args: {'n_agents': 3, 'episode_limit': 300, 'width': 30, 'height': 30, 'extraction_tl': [25, 25], 'extraction_br': [29, 29], 'seed': 4218301, 'ghost_move_prob': 1, 'spawn_radius': 15, 'reward_kill': 100, 'reward_surrounded': 5, 'reward_new_surround': 10, 'lambda_quadrant_coverage': 0.7, 'lambda_ghost_dist_to_extraction': 0.1, 'lambda_agent_dist_to_ghost': 1.0, 'map_name': 'ghostbusters_stage2', 'key': 'ghostbusters_stage2', 'render': False, 'render_every': 1}
epsilon_anneal_time: 300000
epsilon_finish: 0.05
epsilon_start: 1.0
evaluate: True
evaluation_epsilon: 0.1
gamma: 0.99
grad_norm_clip: 5
hidden_dim: 64
hypergroup: None
hypernet_embed: 64
hypernet_layers: 2
label: default_label
learner: q_learner
learner_log_interval: 2000
load_step: 0
local_results_path: results
log_interval: 2000
lr: 0.0003
mac: basic_mac
mask_before_softmax: False
mixer: qmix
mixing_embed_dim: 32
n_actions: 9
n_agents: 3
name: ghostbusters_qmix
obs_agent_id: False
obs_last_action: False
optim_alpha: 0.99
optim_eps: 1e-05
optimizer: adam
render: True
repeat_id: 1
reward_scalarisation: sum
reward_standardisation_alpha: 0.01
rnn_hidden_dim: 128
runner: episode
runner_log_interval: 2000
save_model: True
save_model_interval: 50000
save_replay: False
seed: 4218301
standardise_returns: False
standardise_rewards: True
state_last_action: False
state_shape: 17
t_max: 600000
target_update_interval: 200
target_update_interval_or_tau: 200
tau: 0.005
test_greedy: True
test_interval: 10000
test_nepisode: 20
unique_token: ghostbusters_qmix_seed4218301_ghostbusters_stage2_2025-11-22 17:24:19.539578
use_cuda: False
use_rnn: True
use_tensorboard: False
use_wandb: False
wandb_mode: offline
wandb_project: None
wandb_save_model: False
wandb_team: None
======================

[INFO 17:24:20] my_main Loading model from results/models/QMIX_Stage3_FullObvCatchOnlyWinner/301025
/Users/mario/Documents/Programming/GhostbustersMARL/pymarl/src/components/episode_buffer.py:93: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/python_variable_indexing.cpp:312.)
  target["filled"][slices] = 1
/Users/mario/Documents/Programming/GhostbustersMARL/pymarl/src/components/episode_buffer.py:105: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/python_variable_indexing.cpp:312.)
  self._check_safe_view(v, target[k][_slices])
/Users/mario/Documents/Programming/GhostbustersMARL/pymarl/src/components/episode_buffer.py:106: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/python_variable_indexing.cpp:312.)
  target[k][_slices] = v.view_as(target[k][_slices])
/Users/mario/Documents/Programming/GhostbustersMARL/pymarl/src/components/episode_buffer.py:110: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/python_variable_indexing.cpp:312.)
  v = target[k][_slices]
/Users/mario/Documents/Programming/GhostbustersMARL/pymarl/src/components/episode_buffer.py:113: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/python_variable_indexing.cpp:312.)
  target[new_k][_slices] = v.view_as(target[new_k][_slices])
Episode return: 694.1343720529746
Episode return: 579.5841137398008
Episode return: 305.80690844233055
