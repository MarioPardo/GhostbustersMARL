[INFO 11:36:13] pymarl Running command 'my_main'
[INFO 11:36:13] pymarl Started run with ID "12"
[DEBUG 11:36:13] pymarl Starting Heartbeat
[DEBUG 11:36:13] my_main Started
[WARNING 11:36:13] my_main CUDA flag use_cuda was switched OFF automatically because no CUDA devices are available!
[INFO 11:36:13] my_main Experiment Parameters:
[INFO 11:36:13] my_main 

{   'action_selector': 'epsilon_greedy',
    'add_value_last_step': True,
    'agent': 'rnn',
    'agent_output_type': 'q',
    'batch_size': 64,
    'batch_size_run': 1,
    'buffer_cpu_only': True,
    'buffer_size': 50000,
    'checkpoint_path': 'results/models/QMIX_PartObv_Stage2_Winner',
    'common_reward': True,
    'critic_lr': 0.0003,
    'double_q': True,
    'env': 'ghostbusters',
    'env_args': {   'episode_limit': 400,
                    'extraction_br': [   29,
                                         29],
                    'extraction_tl': [   25,
                                         25],
                    'ghost_move_prob': 1,
                    'height': 30,
                    'key': 'ghostbusters_partobv_stage2',
                    'lambda_agent_dist_to_ghost': 2,
                    'lambda_agent_spread': 1.0,
                    'lambda_ghost_dist_to_extraction': 0.1,
                    'lambda_grid_coverage': 0.5,
                    'lambda_quadrant_coverage': 0.2,
                    'map_name': 'ghostbusters_partobv_stage2',
                    'n_agents': 3,
                    'render': False,
                    'render_every': 1,
                    'reward_ghost_spotted': 20,
                    'reward_ghost_visible': 0.5,
                    'reward_kill': 200,
                    'reward_new_surround': 8,
                    'reward_surrounded': 5,
                    'seed': 560317992,
                    'spawn_radius': 15,
                    'vision_radius': 5,
                    'width': 30},
    'epsilon_anneal_time': 450000,
    'epsilon_finish': 0.05,
    'epsilon_start': 1,
    'evaluate': True,
    'evaluation_epsilon': 0.1,
    'gamma': 0.99,
    'grad_norm_clip': 5,
    'hidden_dim': 64,
    'hypergroup': None,
    'hypernet_embed': 64,
    'hypernet_layers': 2,
    'label': 'default_label',
    'learner': 'q_learner',
    'learner_log_interval': 2000,
    'load_step': 0,
    'local_results_path': 'results',
    'log_interval': 2000,
    'lr': 0.0003,
    'mac': 'basic_mac',
    'mask_before_softmax': False,
    'mixer': 'qmix',
    'mixing_embed_dim': 32,
    'name': 'ghostbusters_qmix',
    'obs_agent_id': False,
    'obs_last_action': False,
    'optim_alpha': 0.99,
    'optim_eps': 1e-05,
    'optimizer': 'adam',
    'render': True,
    'repeat_id': 1,
    'reward_scalarisation': 'sum',
    'reward_standardisation_alpha': 0.01,
    'rnn_hidden_dim': 128,
    'runner': 'episode',
    'runner_log_interval': 2000,
    'save_model': True,
    'save_model_interval': 50000,
    'save_replay': False,
    'seed': 560317992,
    'standardise_returns': False,
    'standardise_rewards': True,
    'state_last_action': False,
    't_max': 800000,
    'target_update_interval': 200,
    'target_update_interval_or_tau': 200,
    'tau': 0.005,
    'test_greedy': True,
    'test_interval': 10000,
    'test_nepisode': 20,
    'use_cuda': False,
    'use_rnn': True,
    'use_tensorboard': False,
    'use_wandb': False,
    'wandb_mode': 'offline',
    'wandb_project': None,
    'wandb_save_model': False,
    'wandb_team': None}

[GhostbustersEnv] Unused env args ignored: ['vision_radius', 'spawn_radius', 'ghost_move_prob', 'reward_kill', 'reward_surrounded', 'reward_new_surround', 'reward_ghost_spotted', 'reward_ghost_visible', 'lambda_agent_spread', 'lambda_grid_coverage', 'lambda_quadrant_coverage', 'lambda_ghost_dist_to_extraction', 'lambda_agent_dist_to_ghost', 'render', 'render_every', 'reward_scalarisation']

===== DEBUG ARGS =====
action_selector: epsilon_greedy
add_value_last_step: True
agent: rnn
agent_output_type: q
batch_size: 64
batch_size_run: 1
buffer_cpu_only: True
buffer_size: 50000
checkpoint_path: results/models/QMIX_PartObv_Stage2_Winner
common_reward: True
critic_lr: 0.0003
device: cpu
double_q: True
env: ghostbusters
env_args: {'n_agents': 3, 'episode_limit': 400, 'width': 30, 'height': 30, 'extraction_tl': [25, 25], 'extraction_br': [29, 29], 'seed': 560317992, 'vision_radius': 5, 'spawn_radius': 15, 'ghost_move_prob': 1, 'reward_kill': 200, 'reward_surrounded': 5, 'reward_new_surround': 8, 'reward_ghost_spotted': 20, 'reward_ghost_visible': 0.5, 'lambda_agent_spread': 1.0, 'lambda_grid_coverage': 0.5, 'lambda_quadrant_coverage': 0.2, 'lambda_ghost_dist_to_extraction': 0.1, 'lambda_agent_dist_to_ghost': 2, 'map_name': 'ghostbusters_partobv_stage2', 'key': 'ghostbusters_partobv_stage2', 'render': False, 'render_every': 1}
epsilon_anneal_time: 450000
epsilon_finish: 0.05
epsilon_start: 1
evaluate: True
evaluation_epsilon: 0.1
gamma: 0.99
grad_norm_clip: 5
hidden_dim: 64
hypergroup: None
hypernet_embed: 64
hypernet_layers: 2
label: default_label
learner: q_learner
learner_log_interval: 2000
load_step: 0
local_results_path: results
log_interval: 2000
lr: 0.0003
mac: basic_mac
mask_before_softmax: False
mixer: qmix
mixing_embed_dim: 32
n_actions: 9
n_agents: 3
name: ghostbusters_qmix
obs_agent_id: False
obs_last_action: False
optim_alpha: 0.99
optim_eps: 1e-05
optimizer: adam
render: True
repeat_id: 1
reward_scalarisation: sum
reward_standardisation_alpha: 0.01
rnn_hidden_dim: 128
runner: episode
runner_log_interval: 2000
save_model: True
save_model_interval: 50000
save_replay: False
seed: 560317992
standardise_returns: False
standardise_rewards: True
state_last_action: False
state_shape: 17
t_max: 800000
target_update_interval: 200
target_update_interval_or_tau: 200
tau: 0.005
test_greedy: True
test_interval: 10000
test_nepisode: 20
unique_token: ghostbusters_qmix_seed560317992_ghostbusters_partobv_stage2_2025-11-25 11:36:13.056255
use_cuda: False
use_rnn: True
use_tensorboard: False
use_wandb: False
wandb_mode: offline
wandb_project: None
wandb_save_model: False
wandb_team: None
======================

[INFO 11:36:14] my_main Loading model from results/models/QMIX_PartObv_Stage2_Winner/752306
/Users/mario/Documents/Programming/GhostbustersMARL/pymarl/src/components/episode_buffer.py:93: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/python_variable_indexing.cpp:312.)
  target["filled"][slices] = 1
/Users/mario/Documents/Programming/GhostbustersMARL/pymarl/src/components/episode_buffer.py:105: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/python_variable_indexing.cpp:312.)
  self._check_safe_view(v, target[k][_slices])
/Users/mario/Documents/Programming/GhostbustersMARL/pymarl/src/components/episode_buffer.py:106: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/python_variable_indexing.cpp:312.)
  target[k][_slices] = v.view_as(target[k][_slices])
[GhostbustersEnv] Initializing pygame display for rendering...
[GhostbustersEnv] Display initialized successfully
/Users/mario/Documents/Programming/GhostbustersMARL/pymarl/src/components/episode_buffer.py:110: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/python_variable_indexing.cpp:312.)
  v = target[k][_slices]
/Users/mario/Documents/Programming/GhostbustersMARL/pymarl/src/components/episode_buffer.py:113: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/python_variable_indexing.cpp:312.)
  target[new_k][_slices] = v.view_as(target[new_k][_slices])
Episode return: 3749.734387087079
Episode return: 3448.167930487789
Episode return: 2202.1403120994382
Episode return: 3124.629752484043
Episode return: 1331.278649784869
Episode return: 1163.228558692187
Episode return: 1388.9374258354155
Episode return: 761.8701809558953
Episode return: 3415.3624988041056
Episode return: 1799.5766156874
Episode return: 1164.9626919239545
Episode return: 1655.2406626473378
